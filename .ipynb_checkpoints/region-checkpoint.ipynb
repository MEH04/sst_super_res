{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba4a584b-8378-44dd-a51f-f07b819ba670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from scipy.signal import windows\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c98a8cfa-bbdf-4f3f-b921-b492b5f0fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(\"SST_ABSO_075.00E_085.00E_10.00S_00.00S_20240101_20240229_region.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c40c1fb-69b7-4f20-ba28-50144ec167fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_spec(image):    \n",
    "    npix = image.shape[0]\n",
    "\n",
    "    fourier_image = np.fft.fftn(image)\n",
    "    fourier_amplitudes = np.abs(fourier_image)**2\n",
    "    kfreq = np.fft.fftfreq(npix) * npix\n",
    "    kfreq2D = np.meshgrid(kfreq, kfreq)\n",
    "    knrm = np.sqrt(kfreq2D[0]**2 + kfreq2D[1]**2)\n",
    "\n",
    "    knrm = knrm.flatten()\n",
    "    fourier_amplitudes = fourier_amplitudes.flatten()\n",
    "\n",
    "    kbins = np.arange(0.5, npix//2+1, 1.)\n",
    "    kvals = 0.5 * (kbins[1:] + kbins[:-1])\n",
    "    Abins, _, _ = stats.binned_statistic(knrm, fourier_amplitudes,\n",
    "                                         statistic = \"mean\",\n",
    "                                         bins = kbins)\n",
    "    Abins *= np.pi * (kbins[1:]**2 - kbins[:-1]**2)\n",
    "    return kvals, Abins\n",
    "\n",
    "def resize(image, split = 48):\n",
    "    ## Resize image so that integer number of split x split sub-grids fit\n",
    "    x_dim = image.shape[0] - image.shape[0]%split\n",
    "    y_dim = image.shape[1] - image.shape[1]%split\n",
    "    image = image[0:x_dim, 0:y_dim]\n",
    "    return image\n",
    "\n",
    "def differentiate(image): \n",
    "    \n",
    "    return x_grad, y_grad\n",
    "\n",
    "def subgrid(image, split = 48):\n",
    "    if image.shape[0]%split != 0:\n",
    "        resize(image, split)\n",
    "    x_subgrids, y_subgrids = int(image.shape[0]/split), int(image.shape[1]/split)\n",
    "    subgridded = np.zeros((x_subgrids, y_subgrids, split, split))\n",
    "    for i in range(x_subgrids):\n",
    "        for j in range(y_subgrids):\n",
    "            subgridded[i,j] = image[i*split:(i+1)*split, j*split:(j+1)*split]\n",
    "    return subgridded\n",
    "\n",
    "def reconstruct_subgrids(subgridded):\n",
    "    x_subgrids, y_subgrids, split_x, split_y = subgridded.shape\n",
    "    reconstructed_image = np.zeros((x_subgrids * split_x, y_subgrids * split_y))\n",
    "    \n",
    "    for i in range(x_subgrids):\n",
    "        for j in range(y_subgrids):\n",
    "            reconstructed_image[i * split_x:(i + 1) * split_x, j * split_y:(j + 1) * split_y] = subgridded[i, j]\n",
    "    return reconstructed_image\n",
    "\n",
    "def apply_model(grad_x, grad_y, model, split=48): \n",
    "    subgridded_x, subgridded_y = subgrid(grad_x,split), subgrid(grad_y,split)\n",
    "    x_grids, y_grids = subgridded_x.shape[0], subgridded_x.shape[1]\n",
    "    stacked = np.stack((subgridded_x, subgridded_y), axis = 0)\n",
    "    gR = np.zeros((2,x_grids,y_grids,subgridded_x.shape[2],subgridded_x.shape[3])) # empty gR array\n",
    "    for i in range(x_grids): \n",
    "        for j in range(y_grids): \n",
    "            subgrid_tensor = torch.from_numpy(stacked[:,i,j])\n",
    "            gR[:,i,j] = model(subgrid_tensor).detach().cpu().numpy()\n",
    "    grad_x_reconstructed = reconstruct_subgrids(gR[0])\n",
    "    grad_y_reconstructed = reconstruct_subgrids(gR[1])\n",
    "    return grad_x_reconstructed, grad_y_reconstructed \n",
    "\n",
    "def absolute_reconstruction(G_x, G_y, l4): \n",
    "    ## Re-construct absolute domain from x and y gradient channels\n",
    "    ## Requires the low-res L4 image as a reference\n",
    "    \n",
    "    dim = G_x.shape[0] # dim x dim image\n",
    "    N = dim**2\n",
    "    \n",
    "    # grad_x matrix operator\n",
    "    grad_x = np.zeros((N,N))\n",
    "    for i in range(N):\n",
    "        if (i+1)%dim != 0:\n",
    "            grad_x[i,i] = -1\n",
    "            grad_x[i,i+1] = 1\n",
    "    \n",
    "    # grad_y matrix operator\n",
    "    grad_y = np.zeros((N,N))\n",
    "    for i in range(N):\n",
    "        if (i+1)//(N-(dim-1)) == 0: \n",
    "            grad_y[i,i] = -1 \n",
    "            grad_y[i,i+dim] = 1\n",
    "    \n",
    "    # now we set-up the equation Ax = b\n",
    "    A = np.matmul(grad_x.transpose(),grad_x) + np.matmul(grad_y.transpose(),grad_y)\n",
    "    \n",
    "    G_x_vec = np.ndarray.flatten(G_x)\n",
    "    G_y_vec = np.ndarray.flatten(G_y)\n",
    "    b = np.matmul(grad_x.transpose(), G_x_vec) + np.matmul(grad_y.transpose(), G_y_vec)\n",
    "    \n",
    "    # solve system of linear equations\n",
    "    solution = np.linalg.solve(A,b)\n",
    "    # re-shape flattened vector to (dim x dim) matrix\n",
    "    reconstructed = np.reshape(solution,(dim,dim))\n",
    "    # scale values\n",
    "    l4_min, l4_max = np.min(l4), np.max(l4)\n",
    "    recon_min, recon_max = np.min(reconstructed), np.max(reconstructed)\n",
    "    normalized_recon = (reconstructed - recon_min) / (recon_max - recon_min)\n",
    "    rescaled_reconstructed = normalized_recon * (l4_max - l4_min) + l4_min\n",
    "    return rescaled_reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5b2fb23-719c-410a-bb7a-500ab35f30b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ERes_Block(nn.Module):\n",
    "    # enhanced residual block\n",
    "    def __init__(self, input_channels = 64):\n",
    "        # define layers\n",
    "        super(ERes_Block, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 64, kernel_size = 3, stride = 1, padding = 'same')\n",
    "        # must return same no. of channels as inputted\n",
    "        self.conv2 = nn.Conv2d(64, input_channels, kernel_size = 3, stride = 1, padding = 'same')\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        x_skip = x # save for skip connection\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.conv2(x) * 0.1\n",
    "        x = torch.add(x,x_skip) # add copy to x\n",
    "        return x\n",
    "        \n",
    "class EDSR(nn.Module): \n",
    "    def __init__(self, input_channels = 1, output_channels = 1, N_blocks=16):\n",
    "        # define layers\n",
    "        super(EDSR, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 64, kernel_size = 3, dilation=1, padding = 'same') # dilation=1\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size = 3, padding = 'same')\n",
    "        self.conv3 = nn.Conv2d(64, output_channels, kernel_size = 3, padding = 'same')\n",
    "        self.erb = ERes_Block(64)\n",
    "        self.N_blocks = N_blocks\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        x=x.float()\n",
    "        x=self.relu(self.conv1(x))\n",
    "        x_skip = x\n",
    "        ## 16 residual blocks\n",
    "        for _ in range(self.N_blocks):\n",
    "            x = self.erb(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = torch.add(x,x_skip)\n",
    "        x = self.conv3(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_path = 'EDSR_Filtered_Data'\n",
    "model = EDSR(2,2).to(device)\n",
    "model.load_state_dict(torch.load(model_path,map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5368cf7-fa83-473d-8e8e-51713b34994d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mds\u001b[49m\u001b[38;5;241m.\u001b[39msst\u001b[38;5;241m.\u001b[39misel(time\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m      2\u001b[0m ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msst_gradx\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39msst\u001b[38;5;241m.\u001b[39mdifferentiate(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msst_grady\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39msst\u001b[38;5;241m.\u001b[39mdifferentiate(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ds' is not defined"
     ]
    }
   ],
   "source": [
    "image = ds.sst.isel(time=3).data\n",
    "ds['sst_gradx'] = ds.sst.differentiate('lat')\n",
    "ds['sst_grady'] = ds.sst.differentiate('lon')\n",
    "sx, sy = ds.sst_gradx.isel(time=0).data,ds.sst_grady.isel(time=0).data\n",
    "gx, gy = apply_model(sx, sy, model)\n",
    "abs_reconstruction = absolute_reconstruction(gx,gy,image)\n",
    "\n",
    "fig,ax=plt.subplots(1,2,figsize=(10,10))\n",
    "ax[0].imshow(image)\n",
    "ax[1].imshow(abs_reconstruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87471120-ccb5-4f73-877f-8f3630fae604",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
